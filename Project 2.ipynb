{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google/applied-machine-learning-intensive/blob/master/content/04_classification/04_classification_project/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2020 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Xt6PXeVjxQN"
      },
      "outputs": [],
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2hPzRb6j_CA"
      },
      "source": [
        "# Classification Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xt6PXeVjxQX"
      },
      "source": [
        "In this project you will apply what you have learned about classification and TensorFlow to complete a project from Kaggle. The challenge is to achieve a high accuracy score while trying to predict which passengers survived the Titanic ship crash. After building your model, you will upload your predictions to Kaggle and submit the score that you get."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDzCkRNv8Kmz"
      },
      "source": [
        "## The Titanic Dataset\n",
        "\n",
        "[Kaggle](https://www.kaggle.com) has a [dataset](https://www.kaggle.com/c/titanic/data) containing the passenger list on the Titanic. The data contains passenger features such as age, gender, ticket class, as well as whether or not they survived.\n",
        "\n",
        "Your job is to create a binary classifier using TensorFlow to determine if a passenger survived or not. The `Survived` column lets you know if the person survived. Then, upload your predictions to Kaggle and submit your accuracy score at the end of this Colab, along with a brief conclusion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4IG3YojoVmk"
      },
      "source": [
        "To get the dataset, you'll need to accept the competition's rules by clicking the \"I understand and accept\" button on the [competition rules page](https://www.kaggle.com/c/titanic/rules). Then upload your `kaggle.json` file and run the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeVKtKt9oTmI"
      },
      "outputs": [],
      "source": [
        "! chmod 600 kaggle.json && (ls ~/.kaggle 2>/dev/null || mkdir ~/.kaggle) && cp kaggle.json ~/.kaggle/ && echo 'Done'\n",
        "! kaggle competitions download -c titanic\n",
        "! ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4VxbBaUpnB6"
      },
      "source": [
        "**Note: If you see a \"403 - Forbidden\" error above, you still need to click \"I understand and accept\" on the [competition rules page](https://www.kaggle.com/c/titanic/rules).**\n",
        "\n",
        "Three files are downloaded:\n",
        "\n",
        "1. `train.csv`: training data (contains features and targets)\n",
        "1. `test.csv`: feature data used to make predictions to send to Kaggle\n",
        "1. `gender_submission.csv`: an example competition submission file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U_zk4L_HpWJ"
      },
      "source": [
        "## Step 1: Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QzpYWY7o0L4"
      },
      "source": [
        "Perform exploratory data analysis and data preprocessing. Use as many text and code blocks as you need to explore the data. Note any findings. Repair any data issues you find."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhhX2RJEyADd"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports and Data"
      ],
      "metadata": {
        "id": "vWKmh-_-C_VC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jR0P7qrDx-n9"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from seaborn.axisgrid import FacetGrid\n",
        "import re\n",
        "from sklearn import linear_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting Data\n",
        "\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "train_df = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "X4U4oV-WCD6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring Taining Data"
      ],
      "metadata": {
        "id": "udktGOOnC10g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "id": "H3q9s-_NCrzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "sRbdBioBGY5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns"
      ],
      "metadata": {
        "id": "zUPLL8lKFozT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the the dataset we know that there is 891 examples. There are 11 features that include name, cabin, ticket, passenger id, sex, age, survived, etc."
      ],
      "metadata": {
        "id": "g0Wqpui5GBrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe()"
      ],
      "metadata": {
        "id": "QqiqnfPoHCAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that according to the dataset 38% of the passangers listed survived. Now we can explore each column"
      ],
      "metadata": {
        "id": "ljGc5KR5H1AV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns = ['Passenger ID', 'Survived', 'P Class', 'Name', 'Sex', \n",
        "                    'Age', 'SibSp', 'Parch', 'Ticket', \n",
        "                    'Fare', 'Cabin', 'Embarked'\n",
        "                 \n",
        "]\n"
      ],
      "metadata": {
        "id": "9QLe4auuInbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns"
      ],
      "metadata": {
        "id": "GHPRYS4TKQ0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['Passenger ID'].isna().any())\n",
        "print(train_df['Passenger ID'].unique().shape)\n",
        "for location in sorted(train_df['Passenger ID'].unique()):\n",
        "  print(location)"
      ],
      "metadata": {
        "id": "Ey8-6dpEK-mH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passenger ID column looks clean"
      ],
      "metadata": {
        "id": "P6jDOa5xMG55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['Survived'].isna().any())\n",
        "\n",
        "print(train_df['Survived'].unique().shape)\n",
        "\n",
        "for location in sorted(train_df['Survived'].unique()):\n",
        "  \n",
        "  print(location)"
      ],
      "metadata": {
        "id": "0IXVqF52MLRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['P Class'].isna().any())\n",
        "\n",
        "print(train_df['P Class'].unique().shape)\n",
        "\n",
        "for location in sorted(train_df['P Class'].unique()):\n",
        "  \n",
        "  print(location)"
      ],
      "metadata": {
        "id": "N2vRGqfcM1bN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['Name'].isna().any())\n",
        "\n",
        "print(train_df['Name'].unique().shape)\n",
        "\n",
        "for location in sorted(train_df['Name'].unique()):\n",
        "\n",
        "  print(location)"
      ],
      "metadata": {
        "id": "s7zx0-ijN_0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['Sex'].isna().any())\n",
        "\n",
        "print(train_df['Sex'].unique().shape)\n",
        "\n",
        "for location in sorted(train_df['Sex'].unique()):\n",
        "\n",
        "  print(location)"
      ],
      "metadata": {
        "id": "RCVFpsYYWlRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['Age'].isna().any())\n",
        "\n",
        "print(train_df['Age'].unique().shape)\n",
        "\n",
        "for location in sorted(train_df['Age'].unique()):\n",
        "\n",
        "  print(location)"
      ],
      "metadata": {
        "id": "o9VQTl5aOzDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['SibSp'].isna().any())\n",
        "\n",
        "print(train_df['SibSp'].unique().shape)\n",
        "\n",
        "for location in sorted(train_df['SibSp'].unique()):\n",
        "\n",
        "  print(location)\n"
      ],
      "metadata": {
        "id": "5RTJEjxBRlH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['Parch'].isna().any())\n",
        "\n",
        "print(train_df['Parch'].unique().shape)\n",
        "\n",
        "for location in sorted(train_df['Parch'].unique()):\n",
        "\n",
        "  print(location)"
      ],
      "metadata": {
        "id": "jHNHdzwQTKCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['Ticket'].isna().any())\n",
        "\n",
        "print(train_df['Ticket'].unique().shape)\n",
        "\n",
        "for location in sorted(train_df['Ticket'].unique()):\n",
        "\n",
        "  print(location)"
      ],
      "metadata": {
        "id": "XvxwLJURTP0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['Fare'].isna().any())\n",
        "\n",
        "print(train_df['Fare'].unique().shape)\n",
        "\n",
        "for location in sorted(train_df['Fare'].unique()):\n",
        "\n",
        "  print(location)"
      ],
      "metadata": {
        "id": "g8p0GZ2QTZX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['Cabin'].isna().any())\n",
        "\n",
        "print(train_df['Cabin'].unique().shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "TAwPWWkcTdLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['Embarked'].isna().any())\n",
        "\n",
        "print(train_df['Embarked'].unique().shape)\n",
        "\\"
      ],
      "metadata": {
        "id": "lC8jQz1_Tidk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRiOrGGW6wW6"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis"
      ],
      "metadata": {
        "id": "5MCpp05XVODf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(10)"
      ],
      "metadata": {
        "id": "6TrIr-M9VTP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns.values"
      ],
      "metadata": {
        "id": "cZF8D-F1VjXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "_ = sns.heatmap(train_df.corr(), cmap='coolwarm', annot=True)"
      ],
      "metadata": {
        "id": "By0P5zbJlRYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FacetGrid = sns.FacetGrid(train_df, row='Embarked')\n",
        "FacetGrid.map(sns.pointplot, 'P Class', 'Survived', 'Sex')\n",
        "FacetGrid.add_legend()"
      ],
      "metadata": {
        "id": "ubh_u2ieVpse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What seems to be the trend is women that was embarked (I'm assuming that means where they are ported at) Q and S had a higher probabilty of survival then women at C. However men at C had a higher chance of survival then men at Q and S. P Class doesnt seem to correlated as well as Embarked. "
      ],
      "metadata": {
        "id": "SRu7RS-PXQjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='Sex', y='Survived', data=train_df)\n"
      ],
      "metadata": {
        "id": "IOwT9TbJYuvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This graph shows that more women survived then men . "
      ],
      "metadata": {
        "id": "8ou5ubBSmbtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Sex'].value_counts()"
      ],
      "metadata": {
        "id": "JvuMqHo2n-mD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There were more male passangers then there were women passangers. "
      ],
      "metadata": {
        "id": "lADqeIreWNWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Survived'].value_counts()"
      ],
      "metadata": {
        "id": "7RGWQjQ5o5BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that 549 people died in this dataset. "
      ],
      "metadata": {
        "id": "qgOgU-csoGlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.pivot_table('Survived', index = 'Sex', columns = 'P Class')"
      ],
      "metadata": {
        "id": "cv7rj7SIgoMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.pivot_table('Survived', index = 'Sex', columns = 'P Class').plot()"
      ],
      "metadata": {
        "id": "huj3m-yGhRu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age = pd.cut(train_df['Age'], [0,18,80])\n",
        "train_df.pivot_table('Survived',['Sex', age], 'P Class')"
      ],
      "metadata": {
        "id": "1hyUylt4icUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary :** What we learn about the data through the anlysis is that there were more men on the titatnic than women. Women had a higher survival rate then men. Women in the Q and S port more likely to survive then women in the C port. Lastly 549 people died and 342 people lived. The last thing we need to do is drop the 'Passenger ID' and 'Cabin' because they do not have a major impact on the survival rate as the other columns. "
      ],
      "metadata": {
        "id": "LPTq_4NFobsR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning Data"
      ],
      "metadata": {
        "id": "oOBOH6EN-MN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the empty vaules in the columns\n",
        "\n",
        "train_df.isna().sum()"
      ],
      "metadata": {
        "id": "t2EXYKHzkl-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A large portion of Cabin is missing so we dont need that but we still need age and embarked"
      ],
      "metadata": {
        "id": "ltvrdT1ik3o_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First we need to see the values type of values in each column\n",
        "\n",
        "for x in train_df:\n",
        "  print(train_df[x].value_counts())\n",
        "  print()"
      ],
      "metadata": {
        "id": "vnZMvYJzlGrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns"
      ],
      "metadata": {
        "id": "9l65XvpwmovW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop the Missing Values in Rows\n",
        "\n",
        "train_df = train_df.dropna(subset = ['Embarked', 'Age'])\n"
      ],
      "metadata": {
        "id": "0-LVE_dAmQSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "id": "e2deTp_SnR_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping the Cabin Column in train data\n",
        "train_df = train_df.drop(['Cabin'], axis=1)"
      ],
      "metadata": {
        "id": "xPNdSSnhn0cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping the Passenger ID, Name, and Ticket column in train data\n",
        "train_df = train_df.drop(['Name', 'Ticket'], axis=1)\n"
      ],
      "metadata": {
        "id": "IXtxtYJmpp5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for the different value types in train data\n",
        "train_df.dtypes"
      ],
      "metadata": {
        "id": "Oq7KSY5nnYXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['Sex'].unique())\n",
        "print(train_df['Embarked'].unique())"
      ],
      "metadata": {
        "id": "Ve58b2Zyq_IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.dtypes"
      ],
      "metadata": {
        "id": "yfDAYWW-D2SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using sklearn to encode columns\n",
        "labelencoder = LabelEncoder()\n",
        "#Sex\n",
        "train_df.iloc[:, 3] = labelencoder.fit_transform(train_df.iloc[:, 3].values)\n",
        "\n",
        "\n",
        "#Embarked\n",
        "train_df.iloc[:, 8] = labelencoder.fit_transform(train_df.iloc[:, 8].values)\n"
      ],
      "metadata": {
        "id": "xrFiu-CqocH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.dtypes"
      ],
      "metadata": {
        "id": "CZRExmBdrUO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "1qSH89Gf40iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxmnIepvmdCx"
      },
      "source": [
        "## Step 2: The Model\n",
        "\n",
        "Build, fit, and evaluate a classification model. Perform any model-specific data processing that you need to perform. If the toolkit you use supports it, create visualizations for loss and accuracy improvements. Use as many text and code blocks as you need to explore the data. Note any findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO8x9d6GHwgQ"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df.drop(\"Survived\", axis=1)\n",
        "Y_train  = train_df[\"Survived\"]\n"
      ],
      "metadata": {
        "id": "dQ1DX5z3NjB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train= sc.fit_transform(X_train)\n"
      ],
      "metadata": {
        "id": "YRWG_MKWuABK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "forest = RandomForestClassifier(n_estimators=10, criterion='entropy',\n",
        "                                random_state = 0)\n",
        "forest.fit(X_train, Y_train)\n",
        "print('[0] Forest Training Accuracy: ', forest.score(X_train, Y_train))"
      ],
      "metadata": {
        "id": "Z6lndHxAtA0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "forest1 = RandomForestClassifier(n_estimators=50, criterion='entropy',\n",
        "                                random_state = 0)\n",
        "forest1.fit(X_train, Y_train)\n",
        "print('[1] Forest Training Accuracy: ', forest1.score(X_train, Y_train))"
      ],
      "metadata": {
        "id": "60wnOoJftFsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "forest2 = RandomForestClassifier(n_estimators=100, criterion='entropy',\n",
        "                                random_state = 0)\n",
        "forest2.fit(X_train, Y_train)\n",
        "print('[2] Forest Training Accuracy: ', forest2.score(X_train, Y_train))"
      ],
      "metadata": {
        "id": "cc4bkaQcrrl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators=1000, criterion='entropy',\n",
        "                                random_state = 0)\n",
        "model.fit(X_train, Y_train)\n",
        "print('[3] Forest Training Accuracy: ', model.score(X_train, Y_train))"
      ],
      "metadata": {
        "id": "DY3SFGDkuYD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model we decided to use was the forest classifier. We saw the higher of the number of estimators the more accurate the model became. "
      ],
      "metadata": {
        "id": "B7TCSne_swAw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT46j3S26sE2"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXJCSsAdz-f0"
      },
      "source": [
        "## Step 3: Make Predictions and Upload To Kaggle\n",
        "\n",
        "In this step you will make predictions on the features found in the `test.csv` file and upload them to Kaggle using the [Kaggle API](https://github.com/Kaggle/kaggle-api). Use as many text and code blocks as you need to explore the data. Note any findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fijeUn4tIFCo"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting Data"
      ],
      "metadata": {
        "id": "K9mpb2ZZ-dBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('test.csv')\n"
      ],
      "metadata": {
        "id": "PnMWxr76y2uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning Data"
      ],
      "metadata": {
        "id": "gyMXQ6IJ-g-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "E30n-NVi4iYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop([ 'Name', 'Ticket', 'Cabin'], axis=1)"
      ],
      "metadata": {
        "id": "selernuLzUQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(7)"
      ],
      "metadata": {
        "id": "UCPKQXal3bhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Sex'].unique())\n",
        "print(df['Embarked'].unique())"
      ],
      "metadata": {
        "id": "cmmKZsdD5XxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "gbt7VJRw5b6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sex\n",
        "df.iloc[:, 2] = labelencoder.fit_transform(test_df.iloc[:, 2].values)\n",
        "\n",
        "\n",
        "#Embarked\n",
        "df.iloc[:, 7] = labelencoder.fit_transform(test_df.iloc[:, 7].values)"
      ],
      "metadata": {
        "id": "_VZM_BYH0AVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.fillna(0)\n"
      ],
      "metadata": {
        "id": "a8mo9RHJ66z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "1E2pflIs7U2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "3yxB4aVHfDwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "1QvOn8vl5rdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "zss8AXlgr960"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Survived'] = np.where(df['Pclass'] >= 2, 0, 1)\n"
      ],
      "metadata": {
        "id": "QcIhoH4DdYvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = df.drop(\"Survived\", axis=1)\n",
        "Y_test  = df[\"Survived\"]"
      ],
      "metadata": {
        "id": "VPKw77RJ-zQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "id": "wfDa6OoNvUtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_test= sc.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "_V5GGbwVqx-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators=100, criterion='entropy',\n",
        "                                random_state = 0)\n",
        "model.fit(X_train, Y_train)\n",
        "print('[3] Forest Training Accuracy: ', model.score(X_train, Y_train))"
      ],
      "metadata": {
        "id": "Z3ZMG0xxw5-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions"
      ],
      "metadata": {
        "id": "13qDKnp8sBqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred =  model.predict(X_test)\n",
        "\n",
        "print(pred)\n",
        "\n",
        "print(Y_test)"
      ],
      "metadata": {
        "id": "sH8SK3EWnVLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "print('Accuracy: ', round(accuracy_score(pred, Y_test), 3))\n",
        "print('Precision: ', round(precision_score(pred, Y_test), 3))\n",
        "print('Recall: ', round(recall_score(pred, Y_test), 3))\n",
        "print('F1: ', round(f1_score(pred, Y_test), 3))"
      ],
      "metadata": {
        "id": "PZKT1w0WrQDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(Y_test, pred).ravel()\n",
        "\n",
        "print(f'True Positive: {tp}\\nTrue Negative: {tn}\\nFalse Positive: {fp}\\nFalse Negative: {fn}')"
      ],
      "metadata": {
        "id": "2sREoRJnrf0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uploading"
      ],
      "metadata": {
        "id": "TgE3DI5cyF9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Submitting to haggle code: \n",
        "results = pd.DataFrame({\n",
        "  'PassengerId': test_df['PassengerId'],\n",
        "  'Survived': pred,\n",
        "})\n",
        "\n",
        "results.to_csv('titanic_predictions.csv', index=False)\n",
        "\n",
        "! head titanic_predictions.csv\n",
        "!kaggle competitions submit -f titanic_predictions.csv -m 'Keras submission' titanic\n",
        "!kaggle competitions submissions titanic\n"
      ],
      "metadata": {
        "id": "VfK-ROyk8h7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRZni-CBVjFV"
      },
      "source": [
        "What was your Kaggle score?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjN-tBAP6kM7"
      },
      "source": [
        "**.674**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSw1rDKv6nOO"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KdtnUJP2Uen"
      },
      "source": [
        "## Step 4: Iterate on Your Model\n",
        "\n",
        "In this step you're encouraged to play around with your model settings and to even try different models. See if you can get a better score. Use as many text and code blocks as you need to explore the data. Note any findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5rYKVkgT8NL"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
        "knn.fit(X_test, Y_test)\n",
        "print('[1] K Neighbors Training Accuracy: ', knn.score(X_test, Y_test))"
      ],
      "metadata": {
        "id": "vMUV-6N-utGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc_lin = SVC(kernel='linear', random_state=0)\n",
        "svc_lin.fit(X_test, Y_test)\n",
        "\n",
        "print('[2] SVC Training Accuracy: ', svc_lin.score(X_test, Y_test))"
      ],
      "metadata": {
        "id": "21nz8po7vCv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc_rbf = SVC(kernel='rbf', random_state=0)\n",
        "svc_rbf.fit(X_test, Y_test)\n",
        "print('[3] RBF Training Accuracy: ', svc_rbf.score(X_test, Y_test))"
      ],
      "metadata": {
        "id": "i2gqu7zHvmFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
        "tree.fit(X_test, Y_test)\n",
        "print('[4] Tree Training Accuracy: ', tree.score(X_test, Y_test))"
      ],
      "metadata": {
        "id": "afpuWNKDwCYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "log = LogisticRegression(random_state= 0)\n",
        "log.fit(X_test, Y_test)\n",
        "\n",
        "\n",
        "print('[5] Logistic Regression Training Accuracy: ', log.score(X_test, Y_test))"
      ],
      "metadata": {
        "id": "oPhY5BYEruzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkyT_lz6_K7E"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the models we used for step four we found the decision tree gave us the best score of  nearly 99% accuracy. "
      ],
      "metadata": {
        "id": "ktGvqc2Tg5rj"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "-U_zk4L_HpWJ",
        "sxmnIepvmdCx",
        "K9mpb2ZZ-dBq",
        "gyMXQ6IJ-g-V",
        "zss8AXlgr960",
        "13qDKnp8sBqP",
        "9KdtnUJP2Uen"
      ],
      "name": "colab.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
