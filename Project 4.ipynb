{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google/applied-machine-learning-intensive/blob/master/content/05_deep_learning/05_image_classification_project/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFwKrxE38t9S"
      },
      "source": [
        "#### Copyright 2020 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpcrMDk48nqI"
      },
      "outputs": [],
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTZOeKjw8waH"
      },
      "source": [
        "# Image Classification Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK5j0BXxrbfX"
      },
      "source": [
        "In this project we will build an image classification model and use the model to identify if the lungs pictured indicate that the patient has pneumonia. The outcome of the model will be true or false for each image.\n",
        "\n",
        "The [data is hosted on Kaggle](https://www.kaggle.com/rob717/pneumonia-dataset) and consists of 5,863 x-ray images. Each image is classified as 'pneumonia' or 'normal'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ht1GVr68swO"
      },
      "source": [
        "## Ethical Considerations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW94_8-98vpR"
      },
      "source": [
        "We will frame the problem as:\n",
        "\n",
        "> *A hospital is having issues correctly diagnosing patients with pneumonia. Their current solution is to have two trained technicians examine every patient scan. Unfortunately, there are many times when two technicians are not available, and the scans have to wait for multiple days to be interpreted.*\n",
        ">\n",
        "> *They hope to fix this issue by creating a model that can identify if a patient has pneumonia. They will have one technician and the model both examine the scans and make a prediction. If the two agree, then the diagnosis is accepted. If the two disagree, then a second technician is brought in to provide their analysis and break the tie.*\n",
        "\n",
        "Discuss some of the ethical considerations of building and using this model. \n",
        "\n",
        "* Consider potential bias in the data that we have been provided. \n",
        "* Should this model err toward precision or accuracy?\n",
        "* What are the implications of massively over-classifying patients as having pneumonia?\n",
        "* What are the implications of massively under-classifying patients as having pneumonia?\n",
        "* Are there any concerns with having only one technician make the initial call?\n",
        "\n",
        "The questions above are prompts. Feel free to bring in other considerations you might have."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgUwTn_K-iK6"
      },
      "source": [
        "### **Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i0zCRDT-j58"
      },
      "source": [
        "> **Question 1:** One bias in the data we have been provided is that all the photos may not be clear enough for our model to really determine if the patients lungs were infected. Looking at some of the pictures while we were doing the exploratory data analysis section, we compared a normal x-ray from the training folder with a infected x-ray from the training folders. If we did not have the titles on we wouldn't know the difference between some the two photos. So we decided to change the code so we plot a image at random. Even then we still couldn't tell the difference. So if human eyes could not spot the difference, the model would not be able to spot the difference if the image is not clear enough. Of course nobody on the team has a medical degree or training in spotting the differences between a infected lung and a normal lung. With that said the easy solution would be to make sure that each x-ray image was clear. Also to use the model aswell with a doctor to give paitents the correct diagnosis. \n",
        "\n",
        "> **Question 2:** A model err towards accuracy will predict how many times a model is correct overall. Whereas precision is more focus on the true and false postives in a model. Since this model will be used to determine whether or not a paintent has preumonia I would prefer for the model to err towards precision over accuracy. I find it less important that the model is right and more important that each paintent that has preumonia is taken account for. \n",
        "\n",
        "> **Question 3:** The implications of massively over-classifying patients as having pneumonia are that people who don't actually have pneumonia will have to undergo treatment and unneccesary hospital visits as if the patient has pneumonia. Another more implication that is more extreme is the model and doctor diagnosing a paintent with pneumonia and they have a even more extreme and fatal such as Tuberculosis and lung cancer which similar to pneumonia affects the lungs.. \n",
        "\n",
        "> **Question 4:** The implications of massively under-classifying patients as having pneumonia is paintent having pneumonia without knowing. This could led to the paitent not getting the neccesary treatment needed and could lead to more serious health concerns. \n",
        "\n",
        "> **Question 5:** Having only one technician make the initial call is very concerning. There should be more then one opinion because leading towards the model or that one doctor could lead to the misdiagnosing discussed already. \n",
        "\n",
        "> Other considerations we have would be to consider using a multiclassifier model. The more information the computer has the better and if there was a model that could predict other lung diseases like lung cancer or tuberculosis it might end up saving lives. Imagine going to the hospital being told you don't have pneumonia, based on the model, and later on find out that you actually have lung cancer. A multiclassifer model would avoid that mistake. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9AxwuxE-nQt"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZFanABOAoHl"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxnS0ZlQAqNj"
      },
      "source": [
        "In this section of the lab, you will build, train, test, and validate a model or models. The data is the [\"Detecting Pneumonia\" dataset](https://www.kaggle.com/rob717/pneumonia-dataset). You will build a binary classifier that determines if an x-ray image has pneumonia or not.\n",
        "\n",
        "You'll need to:\n",
        "\n",
        "* Download the dataset\n",
        "* Perform EDA on the dataset\n",
        "* Build a model that can classify the data\n",
        "* Train the model using the training portion of the dataset. (It is already split out.)\n",
        "* Test at least three different models or model configurations using the testing portion of the dataset. This step can include changing model types, adding and removing layers or nodes from a neural network, or any other parameter tuning that you find potentially useful. Score the model (using accuracy, precision, recall, F1, or some other relevant score(s)) for each configuration.\n",
        "* After finding the \"best\" model and parameters, use the validation portion of the dataset to perform one final sanity check by scoring the model once more with the hold-out data.\n",
        "* If you train a neural network (or other model that you can get epoch-per-epoch performance), graph that performance over each epoch.\n",
        "\n",
        "Explain your work!\n",
        "\n",
        "> *Note: You'll likely want to [enable GPU in this lab](https://colab.research.google.com/notebooks/gpu.ipynb) if it is not already enabled.*\n",
        "\n",
        "If you get to a working solution you're happy with and want another challenge, you'll find pre-trained models on the [landing page of the dataset](https://www.kaggle.com/paultimothymooney/detecting-pneumonia-in-x-ray-images). Try to load one of those and see how it compares to your best model.\n",
        "\n",
        "Use as many text and code cells as you need to for your solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XM35vYWSbim"
      },
      "source": [
        "### **Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports"
      ],
      "metadata": {
        "id": "8W7m-wJJglok"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivTzfzQN5jDk"
      },
      "outputs": [],
      "source": [
        "# Imports \n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keras Libraries\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "a_GAxbW_yujE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dowloading Data Using Kaggle"
      ],
      "metadata": {
        "id": "91ejGDBV0DKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -U -q kaggle\n",
        "!mkdir  /root/.kaggle\n",
        "\n",
        "# Upload kdggle.json api\n",
        "files.upload()\n",
        "!cp kaggle.json /root/.kaggle\n",
        "\n",
        "# Dowloading the Chest X-Ray Pneumonia file from Kaggle\n",
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ],
      "metadata": {
        "id": "qo4LdNVoaiBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code allows us to unzip the file and remove it from this notebooks files\n",
        "!apt install pv\n",
        "!unzip -o /content/chest-xray-pneumonia.zip  | pv -l >/dev/null\n",
        "os.remove('chest-xray-pneumonia.zip')"
      ],
      "metadata": {
        "id": "COFoN3YGakWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting Chest X-Ray file to Data \n",
        "data_dir  = '/content/chest_xray/'\n",
        "\n",
        "# Setting our training data\n",
        "train_dir = data_dir+'train/'\n",
        "\n",
        "# Setting our testing data\n",
        "test_dir  = data_dir+'test/'\n",
        "\n",
        "# Setting our validation data\n",
        "val_dir   = data_dir + 'val/'\n",
        "\n",
        "\n",
        "\n",
        "# Setting the Normal files in the training data to Normal cases\n",
        "normal_cases_dir = train_dir + 'NORMAL/'\n",
        "\n",
        "# Setting the Pneumonia files in the training data to Pneumonia cases\n",
        "pneumonia_cases_dir = train_dir + 'PNEUMONIA/'\n",
        "\n",
        "# This prints the list in each directory \n",
        "print(\"Datasets:\\t\",os.listdir(data_dir))\n",
        "print(\"Train:\\t\", os.listdir(train_dir))\n",
        "print(\"Test:\\t\", os.listdir(test_dir))\n"
      ],
      "metadata": {
        "id": "LnzcuwBIbHGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "nB7iYtAl5qih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The default input size for this model is 224x224.\n",
        "image_size = 150 \n",
        "\n",
        "# Number of files in training set\n",
        "nb_train_samples = 5216 \n",
        "\n",
        "# Number of files in test set\n",
        "num_of_test_samples = 624 \n",
        "\n",
        "# The model will take 16 random batches of files at a time during training\n",
        "batch_size = 16 \n",
        "\n",
        "# We will run this model for 20 epochs(1 epoch = whole dataset traversion during training)\n",
        "EPOCHS = 6 \n",
        "\n",
        "# The model will take 326 steps to complete per batch trainin\n",
        "STEPS = nb_train_samples // batch_size "
      ],
      "metadata": {
        "id": "k6fYXBUObNJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots pie chart of the number of images in the normal and pneumonia cases\n",
        "x = (len(normal_cases_dir), len(pneumonia_cases_dir))\n",
        "labels = ['PNEUMONIA', 'NORMAL']\n",
        "color = ['green', 'yellow']\n",
        "plt.pie(x, labels = labels, colors = color, autopct = '%.0f%%', radius = 1.5, textprops = {'fontsize':16})\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JVsl0qycbjAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normal picture\n",
        "print(len(normal_cases_dir))\n",
        "rand_norm= np.random.randint(0,len(normal_cases_dir))\n",
        "norm_pic = os.listdir(normal_cases_dir)[rand_norm]\n",
        "print('Normal Picture Title: ',norm_pic)\n",
        "\n",
        "norm_pic_address = normal_cases_dir + norm_pic\n",
        "\n",
        "# Pneumonia picture\n",
        "rand_p = np.random.randint(0,len(pneumonia_cases_dir))\n",
        "\n",
        "sic_pic =  os.listdir(pneumonia_cases_dir)[rand_norm]\n",
        "sic_address = pneumonia_cases_dir + sic_pic\n",
        "print('Pneumonia Picture Title:', sic_pic)\n"
      ],
      "metadata": {
        "id": "1NQbM-U0b_dY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the images\n",
        "norm_load = Image.open(norm_pic_address)\n",
        "sic_load = Image.open(sic_address)\n",
        "\n",
        "# Plots the image\n",
        "f = plt.figure(figsize= (10,6))\n",
        "a1 = f.add_subplot(1,2,1)\n",
        "img_plot = plt.imshow(norm_load)\n",
        "a1.set_title('Normal')\n",
        "\n",
        "a2 = f.add_subplot(1, 2, 2)\n",
        "img_plot = plt.imshow(sic_load)\n",
        "a2.set_title('Pneumonia')"
      ],
      "metadata": {
        "id": "3qfgaykpcSAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Looking at the two images used for the exploratory data analysis it is hard to note the difference between the two x-rays and if the title wasn't use we could potentially misdiagnosis a paitent. \n",
        "\n"
      ],
      "metadata": {
        "id": "GU4OMRytqaiy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CNN Model"
      ],
      "metadata": {
        "id": "r9QwXc9EfNzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We decided to use a Neural Network Model\n",
        "cnn = Sequential()\n",
        "\n",
        "\n",
        "cnn.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 3)))\n",
        "\n",
        "\n",
        "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "cnn.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
        "\n",
        "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "cnn.add(Flatten())\n",
        "\n",
        "cnn.add(Dense(activation = 'relu', units = 128))\n",
        "cnn.add(Dense(activation = 'sigmoid', units = 1))\n",
        "\n",
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "K2_6ZPRWeH3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_test_samples = 600\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "SbM26XYQeYrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)  \n",
        "\n",
        "training_set = train_datagen.flow_from_directory(train_dir,\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(val_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(test_dir,\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "metadata": {
        "id": "RiTJFUo_ema9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary of model\n",
        "cnn.summary()\n"
      ],
      "metadata": {
        "id": "_fAW2reWfJ1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = cnn.fit_generator(training_set,\n",
        "                         steps_per_epoch = 163,\n",
        "                         epochs = 5,\n",
        "                         validation_data = validation_generator,\n",
        "                         validation_steps = 624)"
      ],
      "metadata": {
        "id": "fR66I3IgfhgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It seems like we got an accuracy of about 93% but lets test farther\n",
        "test_accu = cnn.evaluate_generator(test_set,steps=624)"
      ],
      "metadata": {
        "id": "dJn3Y-q2gEt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The testing accuracy is :',test_accu[1]*100, '%')\n"
      ],
      "metadata": {
        "id": "HaFgPDwSiQ4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = cnn.predict_generator(test_set, 100)\n",
        "y_pred = np.argmax(Y_pred, axis=1)"
      ],
      "metadata": {
        "id": "GmYuvP6TiYDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnn_model.history['acc'])\n",
        "plt.plot(cnn_model.history['val_acc'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training set', 'Validation set'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZYRu0EKIie03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnn_model.history['val_loss'])\n",
        "plt.plot(cnn_model.history['loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training set', 'Test set'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UJKYBdFlim1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5AaFcUV8NCB"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "yFwKrxE38t9S",
        "8W7m-wJJglok"
      ],
      "name": "colab.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
